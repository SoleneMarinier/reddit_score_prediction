{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A01bhqeaN6R4"
   },
   "source": [
    "## TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we implement TF-IDF so we can later implement it in our model. The goal is to determine which are the frequent words that may play a role into getting a highly-scored comment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input your repository path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repsource = \"C:/Users/s1027177/OneDrive - Syngenta/Documents/FOAD/au_secours/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1=open(repsource+\"df_body_cleaned\",\"rb\")\n",
    "df_cleaned=pickle.load(file1)\n",
    "file1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xVopJGhadMSd"
   },
   "source": [
    "In traditional NLP, we represent words with occurrence vectors. TF-IDF consists in the term count divided by document count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_3nH9EJFM_T"
   },
   "source": [
    "TfidfVectorizer parameter values:\n",
    "\n",
    "* Filter out words that appear in lesS than 1% of the comments\n",
    "* Use the idf\n",
    "* Keep only `number_of_dimensions` words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i-Kup22faQJI"
   },
   "outputs": [],
   "source": [
    "number_of_dimensions = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0SOnVHf7NzI0"
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(\n",
    "    analyzer='word',\n",
    "    ngram_range=(1, 1),\n",
    "    max_features=number_of_dimensions, \n",
    "    min_df=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_split(dataset):\n",
    "    Test_DF = dataset[pd.isna(dataset.ups)]\n",
    "    return Test_DF\n",
    "\n",
    "def train_split(dataset):\n",
    "    Train_DF = dataset[pd.isna(dataset.ups) == False]\n",
    "    return Train_DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_DF = train_split(df_cleaned)\n",
    "Test_DF = test_split(df_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Train_DF.shape)\n",
    "print(Test_DF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text = Train_DF['body']\n",
    "test_text = Test_DF['body']\n",
    "#all_text = pd.concat([train_text, test_text])\n",
    "#all_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit TF-IDF to learn vocabulary on the pre-processed `body` variable and return the document-term matrix for both train and test sets. We save them in a pickle file because it time and space consuming (RAM)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf.fit(train_text)\n",
    "train_word_features = tfidf.transform(train_text)\n",
    "test_word_features = tfidf.transform(test_text)\n",
    "feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2=open(repsource+\"word_features\",\"wb\")\n",
    "pickle.dump(train_word_features,file2)\n",
    "pickle.dump(test_word_features,file2)\n",
    "file2.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert into dataframes and transpose to get the frequencies per term for the words with largest tf-idf terms across all comments in the train set to build a word cloud. This visualization technique is used to represent text data. The size of each word indicates its frequency or importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_features = pd.DataFrame(train_word_features.toarray(), columns=feature_names)\n",
    "test_df_features = pd.DataFrame(test_word_features.toarray(), columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file6=open(repsource+\"word_df_features\",\"wb\")\n",
    "pickle.dump(train_df_features,file6)\n",
    "pickle.dump(test_df_features,file6)\n",
    "file6.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_df_features.shape)\n",
    "print(test_df_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cloud = WordCloud(background_color=\"white\", max_words=100).generate_from_frequencies(train_df_features.T.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(Cloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After looking at the TF-IDF matrix and this workcloud, it seems that we could have done POS tagging to apply TF-IDF on nouns only or extend our stop word list. Another problem is that we don't capture the semantic meaning of the words or their association. We better use word embeddings. We do it in the notebook `022_word_association`."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
