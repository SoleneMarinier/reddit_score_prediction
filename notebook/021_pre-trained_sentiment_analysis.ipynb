{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W04hJbQyAhyU"
   },
   "source": [
    "## Pre-trained Sentiment Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To analyse the comments, a sentiment analysis could be interesting. We want to determine how much positive/negative or neutral are our comments attributing them a score. \n",
    "\n",
    "The intuition behind is that positive comments might stand out more and get more upvotes.\n",
    "\n",
    "In our last notebook, we will implement this sentiment analysis in our final model for score prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AZRmMD0JBAdK"
   },
   "source": [
    "Some Python libraries offers sentiment analysis implementations for textual data. The models of such libraries are pre-trained, meaning we do not need to train our own sentiment analysis model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tqdm.exe is installed in 'C:\\Users\\Solene\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script nltk.exe is installed in 'C:\\Users\\Solene\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading nltk-3.6.1-py3-none-any.whl (1.5 MB)\n",
      "Collecting regex\n",
      "  Downloading regex-2021.4.4-cp39-cp39-win_amd64.whl (270 kB)\n",
      "Collecting click\n",
      "  Using cached click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "Requirement already satisfied: joblib in c:\\users\\solene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk) (1.0.0)\n",
      "Collecting tqdm\n",
      "  Downloading tqdm-4.60.0-py2.py3-none-any.whl (75 kB)\n",
      "Installing collected packages: tqdm, regex, click, nltk\n",
      "Successfully installed click-7.1.2 nltk-3.6.1 regex-2021.4.4 tqdm-4.60.0\n"
     ]
    }
   ],
   "source": [
    "! pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting textblob\n",
      "  Downloading textblob-0.15.3-py2.py3-none-any.whl (636 kB)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\solene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from textblob) (3.6.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\solene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk>=3.1->textblob) (1.0.0)\n",
      "Requirement already satisfied: regex in c:\\users\\solene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk>=3.1->textblob) (2021.4.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\solene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk>=3.1->textblob) (4.60.0)\n",
      "Requirement already satisfied: click in c:\\users\\solene\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.9_qbz5n2kfra8p0\\localcache\\local-packages\\python39\\site-packages (from nltk>=3.1->textblob) (7.1.2)\n",
      "Installing collected packages: textblob\n",
      "Successfully installed textblob-0.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i4nbeZ-gjgos",
    "outputId": "41507037-de77-436d-9a15-1853038da2e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Solene\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input your repository path here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repsource = \"C:/Users/s1027177/OneDrive - Syngenta/Documents/FOAD/au_secours/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file=open(repsource+\"df_inter\",\"rb\")\n",
    "df=pickle.load(file)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-trained sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(df, colname):\n",
    "    \n",
    "    '''\n",
    "      This function computes sentiment scores for a comment using the textblob library.\n",
    "      It has to be applied on raw data (not preprocessed).\n",
    "      Scores are ratio of positive/negative/neutral sentences over the number of sentences\n",
    "      in the comment. Positive, negative and neutral sentiment sentences are defined based\n",
    "      on sentiment polarities' thresholds.\n",
    "\n",
    "      Parameters \n",
    "      ----------\n",
    "      df: pandas.Dataframe\n",
    "        Raw data\n",
    "          \n",
    "      colname: string\n",
    "        Name of the column containing text from raw data.\n",
    "\n",
    "      Returns\n",
    "      -------\n",
    "      df: pandas.Dataframe\n",
    "        pandas.Dataframe with new columns for values of the three ratios.\n",
    "\n",
    "    '''\n",
    "\n",
    "    for idx, com in df[colname].items():\n",
    "\n",
    "        if isinstance(com, str) and com!='deleted' and com!='[deleted]':\n",
    "            blob = TextBlob(com)\n",
    "            pos = 0\n",
    "            neg = 0\n",
    "            neutral = 0\n",
    "            count = 0\n",
    "            for sentence in blob.sentences:\n",
    "                sentiment = sentence.sentiment.polarity\n",
    "                if sentiment > 0.1:\n",
    "                    pos +=1\n",
    "                elif sentiment > -0.1:\n",
    "                    neutral +=1\n",
    "                else:\n",
    "                    neg +=1\n",
    "                count+=1\n",
    "            if count == 0:\n",
    "                count = 1\n",
    "\n",
    "            scores = {\"pos\": pos/count,\n",
    "                      \"neutral\": neutral/count,\n",
    "                      \"neg\": neg/count\n",
    "                     }\n",
    "            \n",
    "        else:\n",
    "            scores = {\"pos\": 0,\n",
    "                    \"neutral\": 0,\n",
    "                    \"neg\": 0\n",
    "                    }\n",
    "            \n",
    "        df.at[idx,'positive_com'] = scores[\"pos\"]\n",
    "        df.at[idx,'neutral_com'] = scores[\"neutral\"]\n",
    "        df.at[idx,'negative_com'] = scores[\"neg\"]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warning ! Executing this function on the raw comments take 4 hours..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df=get_sentiment(df, 'body')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3=open(repsource+\"new_df\",\"wb\")\n",
    "pickle.dump(new_df,file3)\n",
    "file3.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will see in the training part that these variables are not very significant. We could have rather built dummy variables taking 1 when the score is maximum between positive, negative and neutral and include only two of them in the model to avoid for multi-colinearity but it's very time consuming so we didn't execute it again. Here below the function to create these dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(df, colname):\n",
    "\n",
    "    df['positive_com'] = 0\n",
    "    df['neutral_com'] = 0\n",
    "    df['negative_com'] = 0\n",
    "\n",
    "    for idx, com in df[colname].items():\n",
    "        if pd.notnull(com) and com!='deleted' and com!='[deleted]':\n",
    "            blob = TextBlob(com)\n",
    "            pos = 0\n",
    "            neg = 0\n",
    "            neutral = 0\n",
    "            count = 0\n",
    "            for sentence in blob.sentences:\n",
    "                sentiment = sentence.sentiment.polarity\n",
    "                if sentiment > 0.1:\n",
    "                    pos +=1\n",
    "                elif sentiment > -0.1:\n",
    "                    neutral +=1\n",
    "                else:\n",
    "                    neg +=1\n",
    "                count+=1\n",
    "            if count == 0:\n",
    "                count = 1\n",
    "            scores = {\"pos\": pos/count,\n",
    "                    \"neutral\": neutral/count,\n",
    "                    \"neg\": neg/count\n",
    "                    }\n",
    "            max_score = max(scores, key=scores.get)\n",
    "\n",
    "            if max_score == 'pos':\n",
    "                df.at[idx,'positive_com'] +=1\n",
    "            elif max_score == 'neutral':\n",
    "                df.at[idx,'neutral_com'] +=1\n",
    "            else:\n",
    "                df.at[idx,'negative_com'] +=1\n",
    "                \n",
    "        else:\n",
    "            df.at[idx,'positive_com'] = 0\n",
    "            df.at[idx,'neutral_com'] = 0\n",
    "            df.at[idx,'negative_com'] = 0\n",
    "\n",
    "    return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
